{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "#For this notebook to work, Python must be 3.6.4 or 3.6.5\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data Set (https://www.kaggle.com/brandao/diabetes)\n",
    "diabetes=pd.read_csv('Insert the file directory', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************************\n",
      "Column names:  Index(['los', 'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient',\n",
      "       'number_diagnoses', 'sex_Female', 'sex_Male', 'age_[0-10)',\n",
      "       'age_[10-20)', 'age_[20-30)', 'age_[30-40)', 'age_[40-50)',\n",
      "       'age_[50-60)', 'age_[60-70)', 'age_[70-80)', 'age_[80-90)',\n",
      "       'age_[90-100)', 'max_glu_serum_>200', 'max_glu_serum_>300',\n",
      "       'max_glu_serum_None', 'max_glu_serum_Norm', 'A1Cresult_>7',\n",
      "       'A1Cresult_>8', 'A1Cresult_None', 'A1Cresult_Norm',\n",
      "       'group_name1_circulatory', 'group_name1_diabetes',\n",
      "       'group_name1_digestive', 'group_name1_genitourinary',\n",
      "       'group_name1_injury', 'group_name1_musculoskeletal',\n",
      "       'group_name1_neoplasms', 'group_name1_other', 'group_name1_respiratory',\n",
      "       'group_name2_circulatory', 'group_name2_diabetes',\n",
      "       'group_name2_digestive', 'group_name2_genitourinary',\n",
      "       'group_name2_injury', 'group_name2_musculoskeletal',\n",
      "       'group_name2_neoplasms', 'group_name2_other', 'group_name2_respiratory',\n",
      "       'group_name3_circulatory', 'group_name3_diabetes',\n",
      "       'group_name3_digestive', 'group_name3_genitourinary',\n",
      "       'group_name3_injury', 'group_name3_musculoskeletal',\n",
      "       'group_name3_neoplasms', 'group_name3_other', 'group_name3_respiratory',\n",
      "       'risk_High', 'risk_HighMedium', 'risk_Low', 'risk_Medium',\n",
      "       'risk_MediumLow', 'risk_Null', 'risk_VeryHigh', 'risk_co_High',\n",
      "       'risk_co_HighMedium', 'risk_co_Low', 'risk_co_Medium',\n",
      "       'risk_co_MediumLow', 'risk_co_Null', 'risk_co_VeryHigh',\n",
      "       'admission_type_descr_Elective', 'admission_type_descr_Emergency',\n",
      "       'admission_type_descr_NULL', 'admission_type_descr_Newborn',\n",
      "       'admission_type_descr_Not Available', 'admission_type_descr_Not Mapped',\n",
      "       'admission_type_descr_Trauma Centre', 'admission_type_descr_Urgent',\n",
      "       'discharge_disposition_grouped_Discharged to home',\n",
      "       'discharge_disposition_grouped_Discharged to rehab, another type of inpatient care institution or short term hospital',\n",
      "       'discharge_disposition_grouped_Discharged/transferred to SNF',\n",
      "       'discharge_disposition_grouped_Discharged/transferred to home with home health service',\n",
      "       'discharge_disposition_grouped_Other',\n",
      "       'admission_source_grouped_Emergency Room',\n",
      "       'admission_source_grouped_Other',\n",
      "       'admission_source_grouped_Physician Referral',\n",
      "       'admission_source_grouped_Transfer from a hospital',\n",
      "       'admission_source_grouped_Transfer from another health care facility'],\n",
      "      dtype='object')\n",
      "*********************************************************************************\n",
      "Number of rows and columns:  (69970, 87)\n",
      "*********************************************************************************\n",
      "[['YES']\n",
      " ['NO']\n",
      " ['NO']\n",
      " ...\n",
      " ['NO']\n",
      " ['NO']\n",
      " ['NO']]\n",
      "(69970, 1)\n"
     ]
    }
   ],
   "source": [
    "#Create the output dataset (Y) and feature dataset (X)\n",
    "X=diabetes.drop(['readmission'], axis = 1)\n",
    "y=diabetes[['readmission']].values\n",
    "#checking x column\n",
    "print('*********************************************************************************')\n",
    "print('Column names: ',X.columns)\n",
    "print('*********************************************************************************')\n",
    "print('Number of rows and columns: ', X.shape)\n",
    "print('*********************************************************************************')\n",
    "#checking y column\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into training and testing, decided on an 80% training and 20% test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardise \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "#standardizing both training and test data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_standardized_train = pd.DataFrame(X_train_scaled, columns = list(X.columns.values))\n",
    "X_standardized_test = pd.DataFrame(X_test_scaled, columns = list(X.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a Logistic Regression using an L1 Regularisation approach and various class weights\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Case 1 (Yes 80%, No 20%)\n",
    "dict={'NO': 0.2, 'YES': 0.8}\n",
    "Log_Reg1 = LogisticRegression(C = 0.01 , penalty = 'l1', class_weight=dict).fit(X_train_scaled, y_train.ravel()) \n",
    "# Case 2 (Yes 70%, No 30%)\n",
    "dict={'NO': 0.3, 'YES': 0.7}\n",
    "Log_Reg2 = LogisticRegression(C = 0.01 , penalty = 'l1', class_weight=dict).fit(X_train_scaled, y_train.ravel()) \n",
    "# Case 3 (Yes 60%, No 40%)\n",
    "dict={'NO': 0.4, 'YES': 0.6}\n",
    "Log_Reg3 = LogisticRegression(C = 0.01 , penalty = 'l1', class_weight=dict).fit(X_train_scaled, y_train.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_Reg1:\n",
      "\n",
      "Confusion matrix:\n",
      "[[12345   394]\n",
      " [ 1090   165]]\n",
      "Accuracy:\n",
      "0.8939545519508361\n",
      "f1 score:\n",
      "0.1819184123484013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94     12739\n",
      "          1       0.30      0.13      0.18      1255\n",
      "\n",
      "avg / total       0.86      0.89      0.88     13994\n",
      "\n",
      "Sensitivity=TP/(TP+FN)\n",
      " 0.1314\n",
      "Specificity=TP/(FP+TN)\n",
      " 0.969\n",
      "\n",
      "Log_Reg2:\n",
      "\n",
      "Confusion matrix:\n",
      "[[12678    61]\n",
      " [ 1209    46]]\n",
      "Accuracy:\n",
      "0.9092468200657424\n",
      "f1 score:\n",
      "0.06754772393538913\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95     12739\n",
      "          1       0.43      0.04      0.07      1255\n",
      "\n",
      "avg / total       0.87      0.91      0.87     13994\n",
      "\n",
      "Sensitivity=TP/(TP+FN)\n",
      " 0.0367\n",
      "Specificity=TP/(FP+TN)\n",
      " 0.995\n",
      "\n",
      "Log_Reg3:\n",
      "\n",
      "Confusion matrix:\n",
      "[[12729    10]\n",
      " [ 1240    15]]\n",
      "Accuracy:\n",
      "0.910676004001715\n",
      "f1 score:\n",
      "0.0234375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95     12739\n",
      "          1       0.60      0.01      0.02      1255\n",
      "\n",
      "avg / total       0.88      0.91      0.87     13994\n",
      "\n",
      "Sensitivity=TP/(TP+FN)\n",
      " 0.0120\n",
      "Specificity=TP/(FP+TN)\n",
      " 0.999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Outputing Model Metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred= Log_Reg1.predict(X_standardized_test)\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Log_Reg1:\\n\")\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "score = Log_Reg1.score(X_standardized_test, y_test)\n",
    "print(\"Accuracy:\\n{}\".format(score))\n",
    "\n",
    "y_test_binary = [0 if x=='NO' else 1 for x in y_test]\n",
    "y_pred_binary = [0 if x=='NO' else 1 for x in y_pred]\n",
    "f1_score=f1_score(y_test_binary, y_pred_binary, pos_label=1, average='binary') \n",
    "print(\"f1 score:\\n{}\".format(f1_score))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_binary, y_pred_binary))\n",
    "print(\"Sensitivity=TP/(TP+FN)\\n 0.1314\")\n",
    "print(\"Specificity=TP/(FP+TN)\\n 0.969\\n\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred= Log_Reg2.predict(X_standardized_test)\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Log_Reg2:\\n\")\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "score = Log_Reg2.score(X_standardized_test, y_test)\n",
    "print(\"Accuracy:\\n{}\".format(score))\n",
    "\n",
    "y_test_binary = [0 if x=='NO' else 1 for x in y_test]\n",
    "y_pred_binary = [0 if x=='NO' else 1 for x in y_pred]\n",
    "f1_score=f1_score(y_test_binary, y_pred_binary, pos_label=1, average='binary') \n",
    "print(\"f1 score:\\n{}\".format(f1_score))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_binary, y_pred_binary))\n",
    "print(\"Sensitivity=TP/(TP+FN)\\n 0.0367\")\n",
    "print(\"Specificity=TP/(FP+TN)\\n 0.995\\n\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred= Log_Reg3.predict(X_standardized_test)\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Log_Reg3:\\n\")\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "score = Log_Reg3.score(X_standardized_test, y_test)\n",
    "print(\"Accuracy:\\n{}\".format(score))\n",
    "\n",
    "y_test_binary = [0 if x=='NO' else 1 for x in y_test]\n",
    "y_pred_binary = [0 if x=='NO' else 1 for x in y_pred]\n",
    "f1_score=f1_score(y_test_binary, y_pred_binary, pos_label=1, average='binary') \n",
    "print(\"f1 score:\\n{}\".format(f1_score))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_binary, y_pred_binary))\n",
    "print(\"Sensitivity=TP/(TP+FN)\\n 0.0120\")\n",
    "print(\"Specificity=TP/(FP+TN)\\n 0.999\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Commentary#\n",
    "\n",
    "The best model in this example would be: Log_Reg1 where the weights given were the highest for the 'Yes' outcome (Yes 80%, No  20%).\n",
    "The biggest reason why I chose this model is because the hospital has stated   that the most important issue for this learning algorithm is that it doesn't   miss any patients at risk of being readmitted. Essentially, the model is justified with having  more False Positives then False Negatives as a person's  life is at risk if they are deemed well but are actually in danger. We can see that as the weight for the 'Yes' outcome increased, the number of False Negatives decreased gradually and as a result, the Sensitivity ratio also increased. Also, the Log_Reg1 model is the better overall model as shown by the highest f1 score    (better overall Precision and Recall)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
